{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk.chunk import RegexpParser\n",
    "import stanfordTaggers.nerTagger.nertclient\n",
    "import stanfordTaggers.posTagger.posclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PART 0:\n",
    "##Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We abtained the source data from IMDb, Wikipedia (via David Bamman and other researchers, Carnegie Mellon University, and the Social Security Administration (see writeup for citations).\n",
    "\n",
    "We first eliminated TV shows and focused on only movies.\n",
    "\n",
    "Then we reduced the movies to ones with 10 or more IMDB reviews so that we only analyze movies with decent infleunce.\n",
    "\n",
    "We then matched the IMDB movie titles with their wikipedia counterparts, and this turned out to be a challenge on its own. Since our IMDB dataset is larger then the wikipedia dataset, many movies have IMDB summaries but not a wikipedia summary. Our final database included movies that have IMDB summaries and/or wikipedia summaries.\n",
    "\n",
    "Lastly, we matched our movies to their country data, and reduced our dataset to just US movies. It contains about 34,000 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PART 1: \n",
    "##Named Entity Recognition Tagging for Movie Summaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import Standford POS Tagger and Stanford NER Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to run StanfordPostTagger and NERTagger, \n",
    "#first download these two packages from http://nlp.stanford.edu/software/CRF-NER.shtml \n",
    "#I saved the downloaded files in lib/\n",
    "post = StanfordPOSTagger('stanfordTaggers/lib/stanford-postagger-2014-08-27/models/english-bidirectional-distsim.tagger', \n",
    "                         'stanfordTaggers/lib/stanford-postagger-2014-08-27/stanford-postagger.jar', 'utf-8') # doctest: +SKIP\n",
    "# post.tag('What is the airspeed of an unladen swallow ?'.split()) # doctest: +SKIP\n",
    "nert = StanfordNERTagger('stanfordTaggers/lib/stanford-ner-2014-08-27/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                         'stanfordTaggers/lib/stanford-ner-2014-08-27/stanford-ner.jar', 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load in cleaned dataset of USA moviews from IMDB and Wikiperida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/input/usamoviedict.array.json') as sample:\n",
    "    sample = json.load(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###More data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of ([[ in the wikipidia summaries\n",
    "for movie in sample:\n",
    "    summaries_wiki = movie[1]['summaries_wikipedia']\n",
    "    if len(summaries_wiki) > 0:\n",
    "        summaries_wiki = re.sub(r'\\s\\(\\[\\[', ' ', summaries_wiki[0])\n",
    "        movie[1]['summaries_wikipedia'][0] = summaries_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pos tagging using nltk.pos_tag\n",
    "#ner tagging using stanford ner tagger\n",
    "def ie_preprocess(document, lower='false', stage=\"pos\"):\n",
    "#     if stage == 'pos':\n",
    "#         sentences = nltk.sent_tokenize(document)\n",
    "#         sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "#         if lower == 'false':\n",
    "#             for sent in sentences:\n",
    "#                 for i in range(len(sent)):\n",
    "#                     if sent[i] != sent[i].lower():\n",
    "#                         sent[i] = sent[i].lower()\n",
    "#         sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "#         return sentences\n",
    "    if stage == \"ner\":\n",
    "        return nertclient.nertclient(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make stanford nert more accurate by seperating the last word\n",
    "# in a sentence from the ending punctuation with a space.\n",
    "def insert_space_before_punct(s):\n",
    "    s = re.sub(r'([.,!?;:])', r' \\1', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pos + ner tag summaries and roles\n",
    "for movie in sample:\n",
    "    summaries_imdb = movie[1][\"summaries_imdb\"]\n",
    "    summaries_wiki = movie[1]['summaries_wikipedia']\n",
    "    roles = movie[1]['roles']\n",
    "    if len(summaries_imdb) > 0:\n",
    "        # sample[i][1][\"summaries_imdb_pos\"] = ie_preprocess(summaries_imdb[0])\n",
    "        sample[i][1][\"summaries_imdb_ner\"] = ie_preprocess(insert_space_before_punct(summaries_imdb[0]), stage=\"ner\")\n",
    "        \n",
    "    if len(summaries_wiki) > 0:\n",
    "        # sample[i][1][\"summaries_wikipedia_pos\"] = ie_preprocess(summaries_wiki[0])\n",
    "        sample[i][1][\"summaries_wikipedia_ner\"] = ie_preprocess(insert_space_before_punct(summaries_wiki[0]), stage='ner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Output NER tagged dataset as json file usamoviedict.sample.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, set):\n",
    "        d = {}\n",
    "        for i in obj:\n",
    "            d[i] = 1\n",
    "        return d\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data/output/', 'usamoviedict.array.json.complete.json'), 'w') as outfile:\n",
    "    json.dump(sample, outfile, ensure_ascii=False, default=set_default)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PART 2: \n",
    "##Lift out character names from summaries, and associate the character names with names from the IMDB role list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load in the previously NER tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/output/usamoviedict.array.json.complete.json') as tagged_data:\n",
    "    sample = json.load(tagged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create a new master dictionary called \"sum_and_char\" containing character names and related info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####First, add new fields \"summaries_combined\" and \"summaries_combined_ner\" in the dataset that stores wikipedia and IMDB summaries into a single string for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine wiki_ner and imdb_nerie\n",
    "for movie in sample:\n",
    "    combined = []\n",
    "    combined_ner = \"\"\n",
    "    if 'summaries_wikipedia_ner' in movie[1]:\n",
    "        combined.extend(movie[1]['summaries_wikipedia'] )\n",
    "        combined_ner = combined_ner + \" \" + (movie[1]['summaries_wikipedia_ner'] )\n",
    "    if 'summaries_imdb_ner' in movie[1]:\n",
    "        combined.extend(movie[1][\"summaries_imdb\"])\n",
    "        combined_ner = combined_ner + \" \" + (movie[1][\"summaries_imdb_ner\"])\n",
    "    movie[1]['summaries_combined'] = combined\n",
    "    movie[1]['summaries_combined_ner'] = combined_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Second, run a customized regex chuncker to lift out tagged names from combined summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a json file containing a list of names for the social security dataset, this file will be used in the person_extractor_and_replacer function. The resulting name_list.json contains 138,036 unique names (93,889 first names, 58,258 last names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/input/names.json') as data:\n",
    "    first_names = json.load(data)\n",
    "with open('data/input/surnames.json') as data2:\n",
    "    last_names = json.load(data2)\n",
    "\n",
    "name_list = []\n",
    "\n",
    "for key, value in first_names.items():\n",
    "    name_list.append(key)\n",
    "for key, value in last_names.items():\n",
    "    name_list.append(key)\n",
    "\n",
    "def set_default(obj):\n",
    "    if isinstance(obj, set):\n",
    "        d = {}\n",
    "        for i in obj:\n",
    "            d[i] = 1\n",
    "        return d\n",
    "    raise TypeError\n",
    "                    \n",
    "with open(os.path.join('data/output/', \"name_list.json\"), 'w') as outfile:\n",
    "    json.dump(set(name_list), outfile, ensure_ascii=False, default=set_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#character name chunking.\n",
    "#1. tag words in summaries that match the Social Security name dataset as \"/PERSON\"\n",
    "#2. chunk together the consective \"/PERSON\" tagged words\n",
    "#3. append to a chunk any number of capitalized word after a '/PERSON\" tagged word (this helps capture the entirity\n",
    "# of a name that spans multiple words. some of the words toward the end may not have been tagged correctly.)\n",
    "\n",
    "def person_extractor_and_replacer(tagged_summary):\n",
    "    with open('data/output/name_list.json', 'r') as json_str:\n",
    "        ssn_names = json.load(json_str)\n",
    "\n",
    "    words = tagged_summary.split()\n",
    "\n",
    "    persons = []\n",
    "    current_person = []\n",
    "\n",
    "    for w in words:\n",
    "        m = re.search('([^/]+)/([A-Z]+)', w)\n",
    "        if m is not None:\n",
    "            body = m.group(1)\n",
    "            klass = m.group(2)\n",
    "            if klass != \"PERSON\":\n",
    "                if body in ssn_names:\n",
    "                    klass = \"PERSON\"\n",
    "\n",
    "            if klass == \"PERSON\":\n",
    "                current_person.append(body)\n",
    "            elif len(current_person) > 0 and re.search('^[A-Z]', w) is not None:\n",
    "                current_person.append(body)\n",
    "            elif len(current_person) > 0:\n",
    "                persons.append(\" \".join(current_person))\n",
    "                current_person = []\n",
    "            # search for matches with social security name list\n",
    "    return persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a new dict called sum_and_char to store summaries and corresponding characters\n",
    "sum_and_char = {}\n",
    "for movie in sample:\n",
    "#     sorting entity_chuncking results into summaries and characters\n",
    "    result = person_extractor_and_replacer(movie[1]['summaries_combined_ner'])\n",
    "    movie_name = movie[0]\n",
    "    if len(result) <= 0:\n",
    "        char_data = {}\n",
    "    else:\n",
    "        char_data = set(result)\n",
    "    sum_and_char[movie_name] = {\"sum\": movie[1]['summaries_combined'][0], \\\n",
    "                                \"char_raw\": char_data,\\\n",
    "                                \"char_info\" : {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Filter character names, and establish the link between filtered character names from summaries and their counter parts in the roles list. Store results in the field char_info dict within the master dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for movie in sample:\n",
    "#     making a bag of words for roles\n",
    "    for role in movie[1]['roles']:\n",
    "        role_words = role['role']\n",
    "        role_bag = re.split(r' |/|\\'|\\\"', role_words)\n",
    "        role['role_bag'] = (set(role_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter char_raw against role list and link char_names with their names in the role list.\n",
    "''' \n",
    "match words in char_raw against roles in role list. the list of actual character names is a subset of char_raw.\n",
    "This is because some of the captured names are not characters (e.g. director, actor, spriris and saints). We filter\n",
    "out the false names by only keeping char_raw names if at least one word in the name has a matched word in the role list.\n",
    "If there is zero word match, discard. If there is at least one\n",
    "match, keep.\n",
    "\n",
    "char_info in sum_and_char use names in the role list as keys, and contains role gender, char names\n",
    "found in summaries, and roles found in summaries\n",
    "\n",
    "The matching selects the highest # of matches between a role and a character name. Ties are broken by selecting the role with\n",
    "the fewest words.\n",
    "'''\n",
    "for key, value in (sum_and_char.items()):\n",
    "    for movie in sample:\n",
    "#     locate correct movie\n",
    "        if movie[0] == key:\n",
    "#             for each filted char name\n",
    "            for name in value['char_raw']:\n",
    "                max_count = 0\n",
    "                max_role = None\n",
    "                max_gen = None\n",
    "#                 tie-breaker on # of words contained in a role_bag\n",
    "                max_role_bag_len = 0\n",
    "\n",
    "                name_split = name.split()\n",
    "#                 for each role\n",
    "                for role in movie[1]['roles']:\n",
    "                    count = 0\n",
    "#                   for each word in char name\n",
    "#                   increment count by 1 every time a word in the char name appears in a role\n",
    "                    for word in name_split:\n",
    "                        if word in role['role_bag']:\n",
    "                            count += 1\n",
    "#                   select the role with the most counts!\n",
    "                    if (count > max_count) or (count == max_count and len(role['role_bag']) < max_role_bag_len):\n",
    "                        max_count = count\n",
    "                        max_role = role['role']\n",
    "                        max_gen = role['gender']\n",
    "                        max_role_bag_len = len(role['role_bag'])\n",
    "                \n",
    "#                 After looping through all roles in the role list, decide which is the max role\n",
    "                if max_count < 1:\n",
    "#                     print(name, \"discarded\")\n",
    "                    pass\n",
    "                else:   \n",
    "                    if max_role not in value['char_info']:\n",
    "                        value['char_info'][max_role] = {'gender':max_gen, 'roles_found_in_sums':[], 'names_found_in_sums':[name]}\n",
    "                    else:\n",
    "                        value['char_info'][max_role]['names_found_in_sums'].append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Lastly, output the master dict sum_and_char as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/output/sum_char_char.complete.initial.json', 'w') as outfile:\n",
    "    json.dump(os.path.join('data/output/sum_and_char', outfile, ensure_ascii=False, default=set_default)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PART 3: \n",
    "###Find roles for character names in summary!\n",
    "###Start by defining several regular expressions to find phrases that link a character's name to her role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "with open('data/output/sum_char_char.complete.initial.json') as sum_and_char:\n",
    "    sum_and_char = json.load(sum_and_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define regex with parenthesis to keep parens from roles from unbalacing re\n",
    "parenstrip = re.compile(r'[()]')\n",
    "parenbracketstrip =re.compile(r'[[\\]()]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex1: 'is a/an'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            #print(char)\n",
    "            subvalue['re_extracted_roles'] = []\n",
    "            \n",
    "            regex_str = re.sub(parenbracketstrip, '', char) + ' is an? ([^.]+?)\\.'\n",
    "            \n",
    "                \n",
    "                \n",
    "            #print(regex_str)\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drew Cabot([[James Thomas\n",
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex2: ', a <role>'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            regex_str = re.sub(parenstrip, '', char) + ', a ([^.]+?)\\.'\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drew Cabot([[James Thomas\n",
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex3: 'named/by the name of'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            regex_str = '^([A-Za-z ]+ )(named|by the name of) ' + re.sub(parenstrip, '', char)\n",
    "            #print(regex_str)\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex4: '<role>(,) name'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            regex_str = '([A-Za-z]+),? ' + re.sub(parenbracketstrip, '', char)\n",
    "            #print(regex_str)\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex5: 'his/her/their <role>'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            regex_str = re.sub(parenbracketstrip, '', char) +',? (his|her|their) (\\S+) '\n",
    "            #print(regex_str)\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head B**** In Charge\n"
     ]
    }
   ],
   "source": [
    "#regex6: 'his/her <word>'\n",
    "for key, value in sum_and_char.items():\n",
    "    for subkey, subvalue in value['char_info'].items():\n",
    "        for char in subvalue['names_found_in_sums']:\n",
    "            regex_str = '[Hh](is|er) ([A-Za-z]+),? ' + re.sub(parenbracketstrip, '', char)\n",
    "            try:\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            except:\n",
    "                print(char)\n",
    "                regex_str = re.escape(char) + ' is an? ([^.]+?)\\.'\n",
    "                p = re.compile(regex_str)\n",
    "                m = p.search(value['sum'])\n",
    "            if m:\n",
    "                subvalue['re_extracted_roles'].append(m.group(1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Tagging the Regex-extracted parts\n",
    "After extracting phrases with the Regex patterns, we tag them to prepare them for chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('sitting', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('bed', 'NN')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posclient.posclient('I am sitting on the bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('sitting', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('bed', 'NN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.tag('I am sitting on the bed'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=0\n",
    "for film in sum_and_char:\n",
    "    for role in sum_and_char[film]['char_info']:\n",
    "        sum_and_char[film]['char_info'][role]['re_roles_tagged']=[posclient.posclient(re_role) for re_role in sum_and_char[film]['char_info'][role]['re_extracted_roles'] if type(re_role)==str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Lift out the roles of characters using chunking\n",
    "A chunking grammar includes or excludes words from the tagged phrases to try to isolate roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = '''CHUNK: \n",
    "                    {^<.*>*?<NN.*>+}\n",
    "                    {<JJ><NN>}\n",
    "                    {<NNP>+}\n",
    "                    {<NN><NNP>}\n",
    "                    }<IN|.*RB|VB.*|TO|.*DT|PRP.*>{\n",
    "'''\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pattern for breaking chunk string output and tags into list\n",
    "chunktag_re = re.compile('\\S+ /[A-Z]{2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Splitting up chunks and isolating role-descriptive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop through films in dictionary and add lists of chunks\n",
    "for film in sum_and_char:\n",
    "    for role in sum_and_char[film]['char_info']:\n",
    "        sum_and_char[film]['char_info'][role]['chunks'] = []\n",
    "        for tagged_role in sum_and_char[film]['char_info'][role]['re_roles_tagged']:\n",
    "            for subtree in cp.parse(tagged_role).subtrees():\n",
    "                if subtree.label() == 'CHUNK':\n",
    "                    sum_and_char[film]['char_info'][role]['chunks'].append(\" \".join([a + \" /\" + b for (a,b) in subtree.leaves()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regex to remove trailing punctuation from chunks\n",
    "strippattern = re.compile(r'\\W$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for film in sum_and_char:\n",
    "    for role in sum_and_char[film]['char_info']:\n",
    "        roleholdinglist= []\n",
    "        for chunk in sum_and_char[film]['char_info'][role]['chunks']:\n",
    "            chunkwords = chunktag_re.findall(chunk) #list of token-tag strings from chunk\n",
    "            chunktemplist = []\n",
    "            for chunkword in chunkwords:\n",
    "                if ((chunkword[:-4] not in role) and (chunkword[:-4] not in roleholdinglist)\n",
    "                    and ((chunkword.split('/')[1] == ('NN')) )):\n",
    "                    chunktemplist.append(chunkword[:-4])\n",
    "            if len(chunktemplist)>0:    \n",
    "                roleholdinglist.append(' '.join(chunktemplist))\n",
    "        if len(roleholdinglist)>0:\n",
    "            sum_and_char[film]['char_info'][role]['roles_found_in_sums'] = [re.sub(strippattern, '', finalrole) for finalrole in roleholdinglist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alison/Nicole': {'chunks': ['sports /NNS reporter /NN',\n",
       "   'colleague /NN',\n",
       "   'colleague /NN',\n",
       "   'neighbor /NN'],\n",
       "  'gender': 'F',\n",
       "  'names_found_in_sums': ['Alison', 'Alison Gardner', 'Nicole Delarusso'],\n",
       "  're_extracted_roles': ['sports reporter, to lose interest in him shortly after they meet',\n",
       "   'colleague',\n",
       "   'colleague',\n",
       "   'neighbor',\n",
       "   'his',\n",
       "   'is',\n",
       "   'is'],\n",
       "  're_roles_tagged': [[['sports', 'NNS'],\n",
       "    ['reporter', 'NN'],\n",
       "    [',', ','],\n",
       "    ['to', 'TO'],\n",
       "    ['lose', 'VB'],\n",
       "    ['interest', 'NN'],\n",
       "    ['in', 'IN'],\n",
       "    ['him', 'PRP'],\n",
       "    ['shortly', 'RB'],\n",
       "    ['after', 'IN'],\n",
       "    ['they', 'PRP'],\n",
       "    ['meet', 'VBP']],\n",
       "   [['colleague', 'NN']],\n",
       "   [['colleague', 'NN']],\n",
       "   [['neighbor', 'NN']],\n",
       "   [['his', 'PRP$']],\n",
       "   [['is', 'VBZ']],\n",
       "   [['is', 'VBZ']]],\n",
       "  'roles_found_in_sums': ['sports reporter', 'colleague', 'neighbor']},\n",
       " 'Bob/Roberto/Beach Jock/Sportscaster/Lincoln Aide': {'chunks': [],\n",
       "  'gender': 'M',\n",
       "  'names_found_in_sums': ['Bob', 'Abraham Lincoln'],\n",
       "  're_extracted_roles': ['by', 'him'],\n",
       "  're_roles_tagged': [[['by', 'IN']], [['him', 'PRP']]],\n",
       "  'roles_found_in_sums': []},\n",
       " 'Elliot': {'chunks': [],\n",
       "  'gender': 'M',\n",
       "  'names_found_in_sums': ['Elliot', 'Elliot Richardson', 'Elliot Richards'],\n",
       "  're_extracted_roles': ['After'],\n",
       "  're_roles_tagged': [[['After', 'IN']]],\n",
       "  'roles_found_in_sums': []},\n",
       " 'San Francisco Pedestrian': {'chunks': [],\n",
       "  'gender': 'M',\n",
       "  'names_found_in_sums': ['San Francisco'],\n",
       "  're_extracted_roles': ['a'],\n",
       "  're_roles_tagged': [[['a', 'DT']]],\n",
       "  'roles_found_in_sums': []},\n",
       " 'The Devil': {'chunks': ['s /NN'],\n",
       "  'gender': 'F',\n",
       "  'names_found_in_sums': ['The'],\n",
       "  're_extracted_roles': ['s'],\n",
       "  're_roles_tagged': [[['s', 'NN']]],\n",
       "  'roles_found_in_sums': ['s']}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_and_char['bedazzled.2000']['char_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#option to output full \n",
    "with open(os.path.join('data/output/', 'sum_and_char.complete.extracted.json'), 'w') as outfile:\n",
    "    json.dump(sum_and_char, outfile, ensure_ascii=False, default=set_default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PART 4:\n",
    "###Result Analysis\n",
    "Aside from allowing one to easily view data for a particular film, this section mostly contains code we used to look at the data.  More detailed analysis is in the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "with open('data/output/sum_and_char.complete.extracted.json') as sum_and_char:\n",
    "    sum_and_char = json.load(sum_and_char)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###To view extracted data for a particular film, enter it into the \"thisfilm\" variable below in the format \"lower case film title.YYYY\" (e.g. 'gone with the wind.1939' )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role from IMDB credit list:  Pete\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Mustachioed Ludovico Technician\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Dim\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Minister\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Billyboy\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Alex\n",
      "\n",
      "Extracted variants: \n",
      "['London']\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Mrs. Alexander\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Georgie\n",
      "\n",
      "Extracted variants: \n",
      "[]\n",
      "\n",
      "\n",
      "*****\n",
      "Role from IMDB credit list:  Julian\n",
      "\n",
      "Extracted variants: \n",
      "['manservant']\n",
      "\n",
      "\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "thisfilm = 'a clockwork orange.1971'\n",
    "\n",
    "for role in sum_and_char[thisfilm]['char_info']:\n",
    "    print('Role from IMDB credit list: ', role)\n",
    "    print('\\nExtracted variants: ')\n",
    "    print(sum_and_char[thisfilm]['char_info'][role]['roles_found_in_sums'])\n",
    "    print('\\n\\n*****')\n",
    "    #for extracted_role in sum_and_char[thisfilm]['char_info']['roles_found_in_sums']:\n",
    "     #   print(extracted_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In futuristic London, Alex  is the leader of his \"droogs\", Pete , Georgie , and Dim , one of many youth gangs in the decaying metropolis. One night, after intoxicating themselves on \"milk plus\", they engage in an evening of \"ultra-violence\", including beating an elderly vagrant , and fighting a rival gang led by Billyboy .Both Burgess\\' novel and Stanley Kubrick\\'s published movie script have this character\\'s name as one word \"Billyboy\" although the Internet Movie Database lists him in the credits with two words \"Billy Boy\". Stealing a car, they drive to the country home of writer F. Alexander Patrick Magee , where they beat Mr. Alexander to the point of crippling him for life. Alex then rapes his wife  while intoning \"Singin\\' in the Rain\". The next day, while truant from school, Alex is approached by probation officer Mr. P. R. Deltoid , who is aware of Alex\\'s violence and cautions him. In response, Alex visits a record store where he picks up two girls. Alex and the girls have sex in a fast-motion scene. After the events of the night before, his droogs express discontent with Alex\\'s petty crimes, demanding more equality and more high-yield thefts. Alex reasserts his leadership by attacking them and throwing them into a canal. That night, Alex invades the mansion of a wealthy \"cat\"-woman , filled with erotic art. While his droogs remain at the front door, Alex bludgeons the woman with a phallic statue. At the climax of the attack, close-ups of the erotic paintings on the walls are barely visible in single-frame sequences. Hearing police sirens, Alex tries to run away, but is betrayed by his droogs. Dim smashes a pint bottle of milk across his face, leaving him stunned and bleeding. Alex is captured and brutally beaten by the police. A gloating Deltoid spits in his face and informs him that the woman subsequently died in the hospital, making him a murderer. Alex is sentenced to 14 years incarceration. Two years into the sentence, the Minister of the Interior  arrives at the prison looking for test subjects for the Ludovico technique, an experimental aversion therapy for rehabilitating criminals within two weeks; Alex readily volunteers. The process involves drugging the subject, strapping him to a chair, propping his eyelids open, and forcing him to watch violent movies. Alex, initially pleased by the violent images he sees, becomes nauseated due to the drugs. He realizes that one of the films\\' soundtracks is by his favourite composer, Ludwig van Beethoven, and that the Ludovico technique will make him sick when he hears the music he loves. He tries unsuccessfully to end the treatment. After two weeks of the Ludovico technique, the Minister of the Interior puts on a demonstration to prove that Alex is \"cured\". He is shown to be incapable of fighting back against an actor  who insults and attacks him, and he becomes violently ill at the sight of a topless woman . Though the prison chaplain  protests at the results, saying that \"there\\'s no morality without choice\", the prison governor  asserts that they are not interested in the moral questions but only \"the means to prevent violence\". Alex is released and finds that his possessions have been confiscated by the police to help make restitution to his victims, and that his parents have rented out his room. Homeless, Alex encounters the same elderly vagrant from before, who attacks him with several other friends. Alex is saved by two policemen but is shocked to discover they are two of his former droogs, Dim and Georgie. They drag Alex to the countryside, where they beat and nearly drown him. The dazed Alex wanders the countryside before coming to the home of Mr Alexander, and collapses. Alex wakes up to find himself being treated by Mr Alexander and his manservant, Julian . Mr Alexander does not recognize Alex as his attacker but has read about his treatment in the newspapers. Seeing Alex as a political weapon to usurp the government, Mr Alexander intends to expose the Ludovico technique as a step toward totalitarianism by way of mind control. As Mr. Alexander prepares to introduce Alex to colleagues , he hears Alex singing \"Singin\\' in the Rain\" in the bath, and the memories of the earlier assault return. With his colleagues\\' help, Mr. Alexander drugs Alex and places him in a locked upstairs bedroom, playing Beethoven\\'s Ninth Symphony through the floor below. Alex, in excruciating pain, throws himself from the window and is knocked unconscious by the fall. Alex wakes up in a hospital, having dreamt about doctors messing around inside his head. While being given a series of psychological tests, Alex finds that he no longer has an aversion to violence. The Minister of the Interior arrives and apologizes to Alex, letting him know that Mr Alexander has been \"put away\". He offers to take care of Alex and get him a job in return for cooperation with his PR counter-offensive. As a sign of goodwill, the Minister brings in a stereo system playing Beethoven\\'s Ninth Symphony. Alex then realizes that instead of an adverse reaction to the music, he sees an image of himself having sex in the snow with a woman in front of an approving crowd dressed in Beethoven-era fashion. He then states, in a sarcastic and menacing voice-over, \"I was cured, all right!\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_and_char[thisfilm]['sum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commastrip=re.compile(r',')\n",
    "roleslist = open('foundroles.csv', 'w')\n",
    "roleslist.write('Role,Gender,Year,Film\\n')\n",
    "\n",
    "\n",
    "overallrolescounter=0\n",
    "discoveredrolescounter=0\n",
    "for film in sum_and_char:\n",
    "        #print(film)\n",
    "        #print(film[-4:])\n",
    "    \n",
    "        for role in sum_and_char[film]['char_info']:\n",
    "            overallrolescounter+=1\n",
    "            #print('\\t', role)\n",
    "            for foundrole in sum_and_char[film]['char_info'][role]['roles_found_in_sums']:\n",
    "                discoveredrolescounter+=1\n",
    "                #print('\\t\\t', foundrole)\n",
    "                roleslist.write((re.sub(commastrip, '', foundrole).lower()))\n",
    "                roleslist.write(',')\n",
    "                roleslist.write(sum_and_char[film]['char_info'][role]['gender'])\n",
    "                roleslist.write(',')\n",
    "                roleslist.write(film[-4:])\n",
    "                roleslist.write(',')\n",
    "                roleslist.write(re.sub(commastrip, '', film[:-5]))\n",
    "                roleslist.write('\\n')\n",
    "        #print('\\n')\n",
    "roleslist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below creates various lists of extracted roles divided by gender, year, and other attributes, on which we performed frequency distributions to obtain results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractedroleslist = []\n",
    "allroleslist = []\n",
    "yeardict = {}\n",
    "genderdict = {}\n",
    "\n",
    "for film in sum_and_char:\n",
    "    for role in sum_and_char[film]['char_info']:\n",
    "        for foundrole in sum_and_char[film]['char_info'][role]['roles_found_in_sums']:\n",
    "                extractedroleslist.append({'role': foundrole, 'gender': sum_and_char[film]['char_info'][role]['gender'], 'year': int(film[-4:])})\n",
    "\n",
    "                \n",
    "                \n",
    "allroleslist = [item['role'].lower() for item in extractedroleslist]\n",
    "malelist=[item['role'].lower() for item in extractedroleslist if item['gender']=='M']\n",
    "femalelist=[item['role'].lower() for item in extractedroleslist if item['gender']=='F']\n",
    "for x in extractedroleslist:\n",
    "    if x['year'] not in yeardict:\n",
    "        yeardict[x['year']] = [x['role'].lower()]\n",
    "    else:\n",
    "        yeardict[x['year']].append(x['role'].lower())\n",
    "\n",
    "for x in extractedroleslist:\n",
    "    if x['role'].lower() not in genderdict:\n",
    "        genderdict[x['role'].lower()] = {'M':0, 'F':0}\n",
    "        genderdict[x['role'].lower()][x['gender']] +=1\n",
    "    else:\n",
    "        genderdict[x['role'].lower()][x['gender']] +=1\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friend', 2156),\n",
       " ('wife', 1679),\n",
       " ('daughter', 1351),\n",
       " ('brother', 1139),\n",
       " ('son', 1135),\n",
       " ('girlfriend', 992),\n",
       " ('sister', 909),\n",
       " ('father', 863),\n",
       " ('mother', 763),\n",
       " ('man', 744),\n",
       " ('husband', 735),\n",
       " ('boyfriend', 625),\n",
       " ('girl', 541),\n",
       " ('woman', 505),\n",
       " ('agent', 475),\n",
       " ('detective', 468),\n",
       " ('partner', 419),\n",
       " ('friends', 401),\n",
       " ('boss', 365),\n",
       " ('student', 352),\n",
       " ('owner', 350),\n",
       " ('officer', 296),\n",
       " ('boy', 284),\n",
       " ('assistant', 279),\n",
       " ('reporter', 275),\n",
       " ('leader', 263),\n",
       " ('lawyer', 261),\n",
       " ('captain', 254),\n",
       " ('director', 252),\n",
       " ('professor', 249),\n",
       " ('cousin', 240),\n",
       " ('star', 227),\n",
       " ('singer', 223),\n",
       " ('attorney', 222),\n",
       " ('manager', 221),\n",
       " ('teacher', 214),\n",
       " ('neighbor', 204),\n",
       " ('lover', 195),\n",
       " ('john', 192),\n",
       " ('s', 187),\n",
       " ('uncle', 186),\n",
       " ('day', 176),\n",
       " ('writer', 171),\n",
       " ('actress', 169),\n",
       " ('worker', 166),\n",
       " ('secretary', 166),\n",
       " ('lieutenant', 166),\n",
       " ('artist', 162),\n",
       " ('school', 161),\n",
       " ('producer', 159),\n",
       " ('businessman', 154),\n",
       " ('cop', 154),\n",
       " ('photographer', 154),\n",
       " ('couple', 144),\n",
       " ('doctor', 144),\n",
       " ('widow', 142),\n",
       " ('law', 141),\n",
       " ('teenager', 138),\n",
       " ('children', 137),\n",
       " ('pilot', 137),\n",
       " ('plays', 136),\n",
       " ('actor', 133),\n",
       " ('brothers', 133),\n",
       " ('niece', 132),\n",
       " ('member', 131),\n",
       " ('life', 128),\n",
       " ('nurse', 127),\n",
       " ('sweetheart', 122),\n",
       " ('driver', 118),\n",
       " ('sheriff', 118),\n",
       " ('gangster', 117),\n",
       " ('film', 117),\n",
       " ('parents', 116),\n",
       " ('sergeant', 115),\n",
       " ('roommate', 114),\n",
       " ('town', 113),\n",
       " ('killer', 109),\n",
       " ('united', 106),\n",
       " ('night', 104),\n",
       " ('rival', 103),\n",
       " ('scientist', 102),\n",
       " ('commander', 100),\n",
       " ('journalist', 99),\n",
       " ('aunt', 98),\n",
       " ('chief', 95),\n",
       " ('colonel', 92),\n",
       " ('colleague', 92),\n",
       " ('time', 91),\n",
       " ('american', 91),\n",
       " ('child', 91),\n",
       " ('rancher', 90),\n",
       " ('nephew', 90),\n",
       " ('president', 89),\n",
       " ('waitress', 88),\n",
       " ('name', 88),\n",
       " ('player', 87),\n",
       " ('author', 86),\n",
       " ('family', 86),\n",
       " ('police', 85),\n",
       " ('coach', 84)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(allroleslist).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate probability of female in a role\n",
    "for role in genderdict:\n",
    "    genderdict[role]['P(F)'] = genderdict[role]['F']/(genderdict[role]['F']+genderdict[role]['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45700\n",
      "25516\n"
     ]
    }
   ],
   "source": [
    "print(len(malelist))\n",
    "print(len(femalelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decadedict = {}\n",
    "for year in yeardict:\n",
    "    if str(year)[:3] not in decadedict:\n",
    "        decadedict[int(str(year)[:3])] = [role for role in yeardict[year]]\n",
    "    else:\n",
    "        for role in yeardict:\n",
    "            decadedict[int(str(year)[:3])].append(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toptenthrudecades = {}\n",
    "for decade in decadedict:\n",
    "    #print(len(decadedict[decade]))\n",
    "        tenlist = nltk.FreqDist(decadedict[decade]).most_common(10)\n",
    "        toptenthrudecades[decade*10] = [(role[0], tenlist.index(role)) for role in tenlist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['friend', 10, 1920], ['daughter', 9, 1920], ['brother', 8, 1920], ['girl', 7, 1920], ['sister', 6, 1920], ['lover', 5, 1920], ['wife', 4, 1920], ['nephew', 3, 1920], ['man', 2, 1920], ['lady', 1, 1920], ['dancer', 10, 1890], ['pioneer', 9, 1890], ['friend', 10, 1990], ['wife', 9, 1990], ['son', 8, 1990], ['daughter', 7, 1990], ['girlfriend', 6, 1990], ['mother', 5, 1990], ['father', 4, 1990], ['man', 3, 1990], ['brother', 2, 1990], ['sister', 1, 1990], ['wife', 10, 1960], ['friend', 9, 1960], ['lover', 8, 1960], ['girl', 7, 1960], ['partner', 6, 1960], ['daughter', 5, 1960], ['man', 4, 1960], ['girlfriend', 3, 1960], ['father', 2, 1960], ['son', 1, 1960], ['friend', 10, 1930], ['daughter', 9, 1930], ['wife', 8, 1930], ['girl', 7, 1930], ['brother', 6, 1930], ['sister', 5, 1930], ['cousin', 4, 1930], ['singer', 3, 1930], ['owner', 2, 1930], ['detective', 1, 1930], ['daughter', 10, 1900], ['sicilian', 9, 1900], ['sweetheart', 8, 1900], ['sprite', 7, 1900], ['musician', 6, 1900], ['poverty', 5, 1900], ['germany', 4, 1900], ['arthur', 3, 1900], ['wife', 2, 1900], ['herb', 1, 1900], ['friend', 10, 2000], ['wife', 9, 2000], ['daughter', 8, 2000], ['girlfriend', 7, 2000], ['brother', 6, 2000], ['son', 5, 2000], ['mother', 4, 2000], ['boyfriend', 3, 2000], ['sister', 2, 2000], ['father', 1, 2000], ['wife', 10, 1970], ['friend', 9, 1970], ['boyfriend', 8, 1970], ['brother', 7, 1970], ['girlfriend', 6, 1970], ['father', 5, 1970], ['officer', 4, 1970], ['man', 3, 1970], ['prison', 2, 1970], ['star', 1, 1970], ['friend', 10, 1940], ['wife', 9, 1940], ['owner', 8, 1940], ['father', 7, 1940], ['daughter', 6, 1940], ['detective', 5, 1940], ['attorney', 4, 1940], ['singer', 3, 1940], ['man', 2, 1940], ['girl', 1, 1940], ['girl', 10, 1910], ['butler', 9, 1910], ['sweetheart', 8, 1910], ['frame', 7, 1910], ['neighbor', 6, 1910], ['painter', 5, 1910], ['city', 4, 1910], ['con artist', 3, 1910], ['baseball', 2, 1910], ['love', 1, 1910], ['friend', 10, 2010], ['man', 9, 2010], ['wife', 8, 2010], ['mother', 7, 2010], ['daughter', 6, 2010], ['girl', 5, 2010], ['sister', 4, 2010], ['boyfriend', 3, 2010], ['son', 2, 2010], ['boy', 1, 2010], ['wife', 10, 1980], ['friend', 9, 1980], ['son', 8, 1980], ['man', 7, 1980], ['daughter', 6, 1980], ['girlfriend', 5, 1980], ['brother', 4, 1980], ['father', 3, 1980], ['husband', 2, 1980], ['sister', 1, 1980], ['wife', 10, 1950], ['daughter', 9, 1950], ['brother', 8, 1950], ['son', 7, 1950], ['father', 6, 1950], ['friend', 5, 1950], ['girlfriend', 4, 1950], ['sister', 3, 1950], ['captain', 2, 1950], ['man', 1, 1950]]\n"
     ]
    }
   ],
   "source": [
    "decadelist = []\n",
    "for decade in toptenthrudecades:\n",
    "    for item in toptenthrudecades[decade]:\n",
    "        decadelist.append([item[0], 10-item[1], decade])\n",
    "print(decadelist)\n",
    "\n",
    "topten = open('decadetopten.csv', 'w')\n",
    "topten.write('Role,Rank,Year\\n')\n",
    "for item in decadelist:\n",
    "    topten.write(item[0])\n",
    "    topten.write(',')\n",
    "    topten.write(str(item[1]))\n",
    "    topten.write(',')\n",
    "    topten.write(str(item[2]))\n",
    "    topten.write('\\n')\n",
    "topten.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allrolesdist = nltk.FreqDist(allroleslist)\n",
    "maledist = nltk.FreqDist(malelist)\n",
    "femaledist = nltk.FreqDist(femalelist)\n",
    "year1984dist = nltk.FreqDist(yeardict[1984])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friend', 2156),\n",
       " ('wife', 1679),\n",
       " ('daughter', 1351),\n",
       " ('brother', 1139),\n",
       " ('son', 1135),\n",
       " ('girlfriend', 992),\n",
       " ('sister', 909),\n",
       " ('father', 863),\n",
       " ('mother', 763),\n",
       " ('man', 744)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allrolesdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('friend', 1457), ('brother', 1125), ('son', 1100), ('father', 802), ('man', 696), ('husband', 692), ('boyfriend', 610), ('detective', 417), ('agent', 380), ('partner', 338), ('boss', 327), ('owner', 283), ('friends', 278), ('boy', 258), ('officer', 249), ('captain', 229), ('leader', 229), ('director', 226), ('lawyer', 224), ('student', 202), ('professor', 196), ('manager', 188), ('attorney', 179), ('uncle', 174), ('reporter', 159), ('assistant', 157), ('cousin', 152), ('lieutenant', 151), ('producer', 142), ('businessman', 141)]\n",
      "[('wife', 1625), ('daughter', 1316), ('girlfriend', 960), ('sister', 889), ('mother', 719), ('friend', 699), ('girl', 500), ('woman', 462), ('actress', 164), ('singer', 154), ('student', 150), ('secretary', 149), ('widow', 134), ('niece', 131), ('friends', 123), ('assistant', 122), ('nurse', 121), ('teacher', 118), ('reporter', 116), ('sweetheart', 100), ('john', 99), ('aunt', 95), ('agent', 95), ('neighbor', 94), ('star', 92), ('cousin', 88), ('teenager', 82), ('waitress', 81), ('partner', 81), ('mistress', 79)]\n"
     ]
    }
   ],
   "source": [
    "print(maledist.most_common(30))\n",
    "print(femaledist.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friend', 19),\n",
       " ('brother', 17),\n",
       " ('wife', 16),\n",
       " ('girlfriend', 15),\n",
       " ('sister', 13),\n",
       " ('son', 10),\n",
       " ('boyfriend', 9),\n",
       " ('friends', 8),\n",
       " ('man', 8),\n",
       " ('father', 7)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year1984dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114922\n",
      "71216\n"
     ]
    }
   ],
   "source": [
    "print(overallrolescounter)\n",
    "print(discoveredrolescounter)"
   ]
  }
 ],
 "metadata": {
  "gist_id": "54cce534cba20a746f2d",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
